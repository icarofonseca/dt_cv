<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<title>Video Capture Example</title>
	<link href="js_example_style.css" rel="stylesheet" type="text/css" />
</head>

<body>
	<h2>Video Capture Example with Lucas-Kanade Optical Flow</h2>
	<p>
		Click <b>Start/Stop</b> button to start or stop the camera capture.<br>
		The <b>videoInput</b> is a &lt;video&gt; element used as OpenCV.js input.
		The <b>canvasOutput</b> is a &lt;canvas&gt; element used as OpenCv.js output.<br>
		To decide the points, we use <b>cv.goodFeaturesToTrack()</b>. We take the first frame, detect some Shi-Tomasi
		corner points in it, then we iteratively track those points using <b>cv.calcOpticalFlowPyrLK</b>.<br>
		The code of &lt;textarea&gt; will be executed when video is started.
		You can modify the code to investigate more.
	</p>
	<div>
		<div class="control"><button id="startAndStop" disabled>Start</button></div>
	</div>
	<p class="err" id="errorMessage"></p>
	<div>
		<table cellpadding="0" cellspacing="0" width="0" border="0">
			<tr>
				<td>
					<canvas id="canvasOutput" width=1280 height=720></canvas>
				</td>
				<td>
					<video id="videoInput" width=1280 height=720></video>
				</td>
				<td></td>
				<td></td>
			</tr>
			<tr>
				<td>
					<div class="caption">canvasOutput</div>
				</td>
				<td>
					<div class="caption">videoInput</div>
				</td>
				<td></td>
				<td></td>
			</tr>
		</table>
	</div>

	<div id="hereresult"></div>

	<script src="https://webrtc.github.io/adapter/adapter-5.0.4.js" type="text/javascript"></script>
	<script src="utils.js" type="text/javascript"></script>

	<script type="text/javascript">
		let utils = new Utils('errorMessage');

		//utils.loadCode('codeSnippet', 'codeEditor');
		//var log1 =[];
		//var log2 =[];

		let streaming = false;
		let videoInput = document.getElementById('videoInput');
		let startAndStop = document.getElementById('startAndStop');
		let canvasOutput = document.getElementById('canvasOutput');
		let canvasContext = canvasOutput.getContext('2d');

		startAndStop.addEventListener('click', () => {
			if (!streaming) {
				utils.clearError();
				utils.startCamera('hd', onVideoStarted, 'videoInput');
			} else {
				utils.stopCamera();
				onVideoStopped();
			}
		});

		function onVideoStarted() {
			streaming = true;
			startAndStop.innerText = 'Stop';
			videoInput.width = videoInput.videoWidth;
			videoInput.height = videoInput.videoHeight;
			//utils.executeCode('codeEditor');

			let video = document.getElementById('videoInput');
			let cap = new cv.VideoCapture(video);

			// parameters for ShiTomasi corner detection
			let [maxCorners, qualityLevel, minDistance, blockSize] = [5, 0.3, 7, 7];

			// parameters for lucas kanade optical flow
			let winSize = new cv.Size(15, 15);
			let maxLevel = 2;
			let criteria = new cv.TermCriteria(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03);

			// create some random colors
			let color = [];
			for (let i = 0; i < maxCorners; i++) {
				color.push(new cv.Scalar(parseInt(Math.random() * 255), parseInt(Math.random() * 255),
					parseInt(Math.random() * 255), 255));
			}

			// take first frame and find corners in it
			let oldFrame = new cv.Mat(video.height, video.width, cv.CV_8UC4);
			cap.read(oldFrame);
			let oldGray = new cv.Mat();
			cv.cvtColor(oldFrame, oldGray, cv.COLOR_RGB2GRAY);
			let p0 = new cv.Mat();
			let none = new cv.Mat();
			cv.goodFeaturesToTrack(oldGray, p0, maxCorners, qualityLevel, minDistance, none, blockSize);

			// Create a mask image for drawing purposes
			let zeroEle = new cv.Scalar(0, 0, 0, 255);
			let mask = new cv.Mat(oldFrame.rows, oldFrame.cols, oldFrame.type(), zeroEle);

			let frame = new cv.Mat(video.height, video.width, cv.CV_8UC4);
			let frameGray = new cv.Mat();
			let p1 = new cv.Mat();
			let st = new cv.Mat();
			let err = new cv.Mat();

			const FPS = 30;
			function processVideo() {
				try {
					if (!streaming) {
						// clean and stop.
						frame.delete(); oldGray.delete(); p0.delete(); p1.delete(); err.delete(); mask.delete();
						return;
					}
					let begin = Date.now();

					// start processing.
					cap.read(frame);
					cv.cvtColor(frame, frameGray, cv.COLOR_RGBA2GRAY);

					// calculate optical flow
					cv.calcOpticalFlowPyrLK(oldGray, frameGray, p0, p1, st, err, winSize, maxLevel, criteria);

					// select good points
					let goodNew = [];
					let goodOld = [];
					document.getElementById("hereresult").innerHTML = "";
					for (let i = 0; i < st.rows; i++) {
						if (st.data[i] === 1) {
							goodNew.push(new cv.Point(p1.data32F[i * 2], p1.data32F[i * 2 + 1]));
							goodOld.push(new cv.Point(p0.data32F[i * 2], p0.data32F[i * 2 + 1]));
							document.getElementById("hereresult").innerHTML += "Centimeter distance from left upmost corner <br />";
							document.getElementById("hereresult").innerHTML += "Point " + goodNew.length + ", x: " + JSON.stringify(Math.round(goodNew[goodNew.length - 1].x / 24.19819214 * 100) / 100) + ", y:" + JSON.stringify(Math.round(goodNew[goodNew.length - 1].y / 24.19819214 * 100) / 100) + "<br />";
							document.getElementById("hereresult").innerHTML += "Pixel distance <br />";
							document.getElementById("hereresult").innerHTML += "Point " + goodNew.length + ", x: " + JSON.stringify(Math.round(goodNew[goodNew.length - 1].x * 100) / 100) + ", y:" + JSON.stringify(Math.round(goodNew[goodNew.length - 1].y * 100) / 100) + "<br />";
							//console.log(st.rows, st);
							//document.getElementById("startAndStop").click();
						}
					}

					//console.log(goodNew);
					//log1.push(goodNew[0]);
					//log2.push(goodNew[1]);

					// draw the tracks
					for (let i = 0; i < goodNew.length; i++) {
						//cv.line(mask, goodNew[i], goodOld[i], color[i], 2);
						cv.circle(frame, goodNew[i], 5, color[i], -1);
					}
					cv.add(frame, mask, frame);

					cv.imshow('canvasOutput', frame);

					// now update the previous frame and previous points
					frameGray.copyTo(oldGray);
					p0.delete(); p0 = null;
					p0 = new cv.Mat(goodNew.length, 1, cv.CV_32FC2);
					for (let i = 0; i < goodNew.length; i++) {
						p0.data32F[i * 2] = goodNew[i].x;
						p0.data32F[i * 2 + 1] = goodNew[i].y;
					}

					// schedule the next one.
					let delay = 1000 / FPS - (Date.now() - begin);
					setTimeout(processVideo, delay);
				} catch (err) {
					utils.printError(err);
					restartCapture();
				}
			};

			// schedule the first one.
			setTimeout(processVideo, 0);
		}

		function onVideoStopped() {
			streaming = false;
			canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
			startAndStop.innerText = 'Start';
		}

		utils.loadOpenCv(() => {
			startAndStop.removeAttribute('disabled');
		});

		function restartCapture() {
			utils.clearError();
			utils.startCamera('hd', onVideoStarted, 'videoInput');
		}
	</script>
</body>

</html>